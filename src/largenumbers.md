# 大数定理

大数定理，也称为大数法则、大数定律。描述了相当多次试验结果的定律$$^{[1]}$$。

大数定理的表现形式：

- 弱大数定理（WLLN），也称为辛钦定理：样本均值依概率收敛$$^{[2]}$$于期望值。

  $$\overline{X}_n\to\mu$$ ，当 $$n\to\infty$$ ，即，对任意正数 $$\epsilon$$ ：

  $$\lim_{n\to\infty}P\left(|\overline{X}_n-\mu|\gt\epsilon\right)=0$$

- 强大数定理（SLLN）：样本均值以概率 $$1$$ 收敛于期望值。

  $$\overline{X}_n\to\mu$$ ，当 $$n\to\infty$$ ，即

  $$P\left(\lim_{n\to\infty}\overline{X}_n=\mu\right)=1$$

- 切比雪夫定理的特殊情况：

  设 $$a_1,a_2,\cdots,a_n,\cdots$$   为相互独立的随机变量，其数学期望为： $$E(a_i)=\mu,\quad(i=1,2,\cdots)$$ ，方差为： $${\rm{Var}}(a_i)=\sigma^2$$ 

  则序列 $$\overline{a}=\frac{1}{n}\sum_{i=1}^na_i$$ 依概率收敛于 $$\mu$$ （即收敛于此数列的数学期望 $$E(a_i)$$ ）

  换言之，在定理条件下，当 $$n$$ 无限变大时，$$n$$ 个随机变量的算术平均将变成一个常数。

- 伯努利大数定律

  设在 $$n$$ 次独立重复伯努利试验中，事件 $$X$$ 发生的次数为 $$n$$ ，事件 $$X$$ 在每次试验中发生的总体概率为 $$p$$ ，$$\frac{n_x}{p}$$ 代表样本发生事件 $$X$$ 的频率。

  则对任意正数 $$\epsilon\gt0$$ ，伯努利大数定律表明：

  $$\lim_{n\to\infty}P\left\{\begin{vmatrix}\frac{n_x}{n}-p\end{vmatrix}\lt\epsilon\right\}=1$$

  換言之，事件发生的频率依概率收敛于事件的总体概率。
  
  該定理以严格的数学形式表达了频率的稳定性，也就是说当 $$n$$ 很大时，事件发生的频率于总体概率有较大偏差的可能性很小。

## 参考资料

[1]. [维基百科：大数定律](https://zh.wikipedia.org/wiki/%E5%A4%A7%E6%95%B8%E6%B3%95%E5%89%87)

[2]. 依概率收敛，是随机变量的收敛方式之一。设 $$(X_n)_{n\ge1}$$ 是一个随机变量序列， $$X$$ 是一个随机变量。如果对于任意的正实数 $$\epsilon\gt0$$ ，都有：

$${\rm{lim}}_{n\to\infty}P(|X-X_n|\ge\epsilon)=0$$

那么称序列 $$(X_n)_{n\ge1}$$ 依概率收敛到 $$X$$ 。

由此可知，依概率收敛，指的是 $$X_n$$ 和 $$X$$ 之间存在差距的可能性将会随着 $$n$$ 的增大而趋于零。

依概率收敛是一种常见的收敛性质。依概率收敛比依分布收敛更强，比平均收敛则要弱。

如果一个随机变量序列依概率收敛到某一个随机变量，则它们也一定依分布收敛到这个随机变量。反过来则不然：只有当一个随机变量序列依分布收敛到一个常数的时候，才能够推出它们也依概率收敛到这个常数$$^{[3]}$$。

[3]. [维基百科：依概率收敛](https://zh.wikipedia.org/wiki/%E4%BE%9D%E6%A6%82%E7%8E%87%E6%94%B6%E6%95%9B)